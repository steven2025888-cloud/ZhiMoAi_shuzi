[MODEL] ÕýÔÚ¼ÓÔØ IndexTTS2 ÉùÑ§Ä£ÐÍ...
>> GPT weights restored from: D:\ZhiMoAi_shuzi\IndexTTS2-SonicVale\checkpoints\gpt.pth
GPT2InferenceModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From \U0001f449v4.50\U0001f448 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
>> Failed to load custom CUDA kernel for BigVGAN. Falling back to torch.
TypeError("unsupported operand type(s) for +: 'NoneType' and 'str'")
>> semantic_codec weights restored from: D:\ZhiMoAi_shuzi\IndexTTS2-SonicVale\checkpoints\hf_cache\models--amphion--MaskGCT\snapshots\265c6cef07625665d0c28d2faafb1415562379dc\semantic_codec\model.safetensors
cfm loaded
length_regulator loaded
gpt_layer loaded
>> s2mel weights restored from: D:\ZhiMoAi_shuzi\IndexTTS2-SonicVale\checkpoints\s2mel.pth
>> campplus_model weights restored from: D:\ZhiMoAi_shuzi\IndexTTS2-SonicVale\checkpoints\hf_cache\models--funasr--campplus\snapshots\fb71fe990cbf6031ae6987a2d76fe64f94377b7e\campplus_cn_common.bin
Loading weights from nvidia/bigvgan_v2_22khz_80band_256x
Removing weight norm...
>> bigvgan weights restored from: nvidia/bigvgan_v2_22khz_80band_256x
>> TextNormalizer loaded
>> bpe model loaded from: D:\ZhiMoAi_shuzi\IndexTTS2-SonicVale\checkpoints\bpe.model
[MODEL] Ä£ÐÍ¼ÓÔØÍê³É£¬ÕýÔÚÔ¤ÈÈÒýÇæ...
>> starting inference...
Use the specified emotion vector
The following generation flags are not valid and may be ignored: ['length_penalty']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.53.0. You should pass an instance of `Cache` instead, e.g. `past_key_values=DynamicCache.from_legacy_cache(past_key_values)`.
  0%|          | 0/25 [00:00<?, ?it/s]  4%|¨…         | 1/25 [00:00<00:02,  9.29it/s] 28%|¨€¨€¨‚       | 7/25 [00:00<00:00, 34.79it/s] 44%|¨€¨€¨€¨€¨…     | 11/25 [00:00<00:00, 26.40it/s] 56%|¨€¨€¨€¨€¨€¨„    | 14/25 [00:00<00:00, 24.06it/s] 68%|¨€¨€¨€¨€¨€¨€¨‚   | 17/25 [00:00<00:00, 22.91it/s] 80%|¨€¨€¨€¨€¨€¨€¨€¨€  | 20/25 [00:00<00:00, 22.16it/s] 92%|¨€¨€¨€¨€¨€¨€¨€¨€¨€¨‡| 23/25 [00:01<00:00, 21.62it/s]100%|¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€| 25/25 [00:01<00:00, 22.74it/s]
torch.Size([1, 21504])
>> gpt_gen_time: 0.85 seconds
>> gpt_forward_time: 0.01 seconds
>> s2mel_time: 1.11 seconds
>> bigvgan_time: 0.26 seconds
>> Total inference time: 3.09 seconds
>> Generated audio length: 0.98 seconds
>> RTF: 3.1653
>> wav file saved to: D:\ZhiMoAi_shuzi\unified_outputs\_warmup.wav
[MODEL] ÒýÇæÔ¤ÈÈÍê³É£¬Ê×´ÎºÏ³É½«Ö±½ÓÊä³ö
[MODEL] OK
[WARMUP] ÕýÔÚÔ¤ÈÈ LatentSync ÒýÇæ...
[WARMUP] LatentSync Ô¤ÈÈ·µ»Ø·ÇÁãÂë: 1
[WARMUP] stderr: Traceback (most recent call last):
  File "<string>", line 1, in <module>
ImportError: cannot import name 'load_model' from 'latentsync.utils.util' (D:\ZhiMoAi_shuzi\LatentSync\latentsync\utils\util.py)

>> starting inference...
Use the specified emotion vector
The following generation flags are not valid and may be ignored: ['length_penalty']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
  0%|          | 0/25 [00:00<?, ?it/s] 24%|¨€¨€¨…       | 6/25 [00:00<00:00, 50.33it/s] 48%|¨€¨€¨€¨€¨‚     | 12/25 [00:00<00:00, 26.72it/s] 64%|¨€¨€¨€¨€¨€¨€¨…   | 16/25 [00:00<00:00, 23.93it/s] 76%|¨€¨€¨€¨€¨€¨€¨€¨„  | 19/25 [00:00<00:00, 22.63it/s] 88%|¨€¨€¨€¨€¨€¨€¨€¨€¨‚ | 22/25 [00:00<00:00, 21.81it/s]100%|¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€| 25/25 [00:01<00:00, 21.30it/s]100%|¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€| 25/25 [00:01<00:00, 23.45it/s]
torch.Size([1, 35584])
>> gpt_gen_time: 1.01 seconds
>> gpt_forward_time: 0.01 seconds
>> s2mel_time: 1.07 seconds
>> bigvgan_time: 0.12 seconds
>> Total inference time: 2.90 seconds
>> Generated audio length: 1.61 seconds
>> RTF: 1.7941
>> wav file saved to: D:\ZhiMoAi_shuzi\unified_outputs\tts_1771698114.wav
[LS] Input video path: D:\ZhiMoAi_shuzi\unified_outputs\in_v_1771698120.mp4
[LS] Input audio path: D:\ZhiMoAi_shuzi\unified_outputs\in_a_1771698120.wav
[LS] Loaded checkpoint path: D:\ZhiMoAi_shuzi\LatentSync\checkpoints\latentsync_unet.pt
[LS] Initial seed: 1247
[LS] video in 25 FPS, audio idx in 50FPS
[LS] Affine transforming 42 faces...
[LS] 0%|          | 0/42 [00:00<?, ?it/s]
[LS] 2%|ï¿½ï¿½         | 1/42 [00:06<04:07,  6.03s/it]
[LS] 5%|ï¿½ï¿½         | 2/42 [00:09<03:02,  4.55s/it]
[LS] 10%|ï¿½ï¿½         | 4/42 [00:09<01:05,  1.74s/it]
[LS] 14%|ï¿½ï¿½ï¿½ï¿½        | 6/42 [00:09<00:33,  1.06it/s]
[LS] 19%|ï¿½ï¿½ï¿½ï¿½        | 8/42 [00:09<00:19,  1.70it/s]
[LS] 24%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½       | 10/42 [00:10<00:12,  2.54it/s]
[LS] 29%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½       | 12/42 [00:10<00:08,  3.59it/s]
[LS] 33%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½      | 14/42 [00:10<00:05,  4.86it/s]
[LS] 38%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½      | 16/42 [00:10<00:04,  6.33it/s]
[LS] 43%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½     | 18/42 [00:10<00:03,  7.92it/s]
[LS] 48%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½     | 20/42 [00:10<00:02,  9.53it/s]
[LS] 52%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½    | 22/42 [00:10<00:01, 10.94it/s]
[LS] 57%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½    | 24/42 [00:10<00:01, 12.37it/s]
[LS] 62%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½   | 26/42 [00:10<00:01, 13.62it/s]
[LS] 67%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½   | 28/42 [00:11<00:00, 14.61it/s]
[LS] 71%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½  | 30/42 [00:11<00:00, 15.38it/s]
[LS] 76%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½  | 32/42 [00:11<00:00, 15.97it/s]
[LS] 81%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½  | 34/42 [00:11<00:00, 16.47it/s]
[LS] 86%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ | 36/42 [00:11<00:00, 16.77it/s]
[LS] 90%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ | 38/42 [00:11<00:00, 17.09it/s]
[LS] 95%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½| 40/42 [00:11<00:00, 17.22it/s]
[LS] 100%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½| 42/42 [00:11<00:00, 17.31it/s]
[LS] 100%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½| 42/42 [00:11<00:00,  3.55it/s]
[LS] Doing inference...:   0%|          | 0/3 [00:00<?, ?it/s]D:\ZhiMoAi_shuzi\LatentSync\latents_env\Lib\site-packages\diffusers\models\attention_processor.py:3286: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\actions-runner\_work\pytorch\pytorch\builder\windows\pytorch\aten\src\ATen\native\transformers\cuda\sdp_utils.cpp:555.)
[LS] hidden_states = F.scaled_dot_product_attention(
[LS] Sample frames: 16:   0%|          | 0/12 [00:00<?, ?it/s][A
[LS] Sample frames: 16:   8%|ï¿½ï¿½         | 1/12 [00:01<00:15,  1.38s/it][A
[LS] Sample frames: 16:  17%|ï¿½ï¿½ï¿½ï¿½        | 2/12 [00:01<00:07,  1.43it/s][A
[LS] Sample frames: 16:  25%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½       | 3/12 [00:01<00:04,  2.07it/s][A
[LS] Sample frames: 16:  33%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½      | 4/12 [00:02<00:03,  2.63it/s][A
[LS] Sample frames: 16:  42%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½     | 5/12 [00:02<00:02,  3.09it/s][A
[LS] Sample frames: 16:  50%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½     | 6/12 [00:02<00:01,  3.45it/s][A
[LS] Sample frames: 16:  58%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½    | 7/12 [00:02<00:01,  3.73it/s][A
[LS] Sample frames: 16:  67%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½   | 8/12 [00:02<00:01,  3.92it/s][A
[LS] Sample frames: 16:  75%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½  | 9/12 [00:03<00:00,  4.08it/s][A
[LS] Sample frames: 16:  83%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ | 10/12 [00:03<00:00,  4.18it/s][A
[LS] Sample frames: 16:  92%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½| 11/12 [00:03<00:00,  4.27it/s][A
[LS] Sample frames: 16: 100%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½| 12/12 [00:03<00:00,  4.32it/s][A
[LS] Sample frames: 16: 100%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½| 12/12 [00:03<00:00,  3.12it/s]
[LS] Doing inference...:  33%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½      | 1/3 [00:07<00:14,  7.40s/it]
[LS] Sample frames: 16:   0%|          | 0/12 [00:00<?, ?it/s][A
[LS] Sample frames: 16:   8%|ï¿½ï¿½         | 1/12 [00:00<00:03,  2.79it/s][A
[LS] Sample frames: 16:  17%|ï¿½ï¿½ï¿½ï¿½        | 2/12 [00:00<00:02,  3.59it/s][A
[LS] Sample frames: 16:  25%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½       | 3/12 [00:00<00:02,  3.94it/s][A
[LS] Sample frames: 16:  33%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½      | 4/12 [00:01<00:01,  4.12it/s][A
[LS] Sample frames: 16:  42%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½     | 5/12 [00:01<00:01,  4.24it/s][A
[LS] Sample frames: 16:  50%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½     | 6/12 [00:01<00:01,  4.31it/s][A
[LS] Sample frames: 16:  58%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½    | 7/12 [00:01<00:01,  4.37it/s][A
[LS] Sample frames: 16:  67%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½   | 8/12 [00:01<00:00,  4.38it/s][A
[LS] Sample frames: 16:  75%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½  | 9/12 [00:02<00:00,  4.39it/s][A
[LS] Sample frames: 16:  83%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ | 10/12 [00:02<00:00,  4.40it/s][A
[LS] Sample frames: 16:  92%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½| 11/12 [00:02<00:00,  4.42it/s][A
[LS] Sample frames: 16: 100%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½| 12/12 [00:02<00:00,  4.44it/s][A
[LS] Sample frames: 16: 100%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½| 12/12 [00:02<00:00,  4.24it/s]
[LS] Doing inference...:  67%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½   | 2/3 [00:10<00:05,  5.02s/it]
[LS] Sample frames: 16:   0%|          | 0/12 [00:00<?, ?it/s][A
[LS] Sample frames: 16:   8%|ï¿½ï¿½         | 1/12 [00:00<00:10,  1.01it/s][A
[LS] Sample frames: 16:  17%|ï¿½ï¿½ï¿½ï¿½        | 2/12 [00:01<00:04,  2.03it/s][A
[LS] Sample frames: 16:  25%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½       | 3/12 [00:01<00:02,  3.00it/s][A
[LS] Sample frames: 16:  33%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½      | 4/12 [00:01<00:02,  3.86it/s][A
[LS] Sample frames: 16:  42%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½     | 5/12 [00:01<00:01,  4.58it/s][A
[LS] Sample frames: 16:  50%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½     | 6/12 [00:01<00:01,  5.19it/s][A
[LS] Sample frames: 16:  58%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½    | 7/12 [00:01<00:00,  5.63it/s][A
[LS] Sample frames: 16:  67%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½   | 8/12 [00:02<00:00,  5.98it/s][A
[LS] Sample frames: 16:  75%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½  | 9/12 [00:02<00:00,  6.26it/s][A
[LS] Sample frames: 16:  83%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ | 10/12 [00:02<00:00,  6.43it/s][A
[LS] Sample frames: 16:  92%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½| 11/12 [00:02<00:00,  6.55it/s][A
[LS] Sample frames: 16: 100%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½| 12/12 [00:02<00:00,  6.65it/s][A
[LS] Sample frames: 16: 100%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½| 12/12 [00:02<00:00,  4.64it/s]
[LS] Doing inference...: 100%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½| 3/3 [00:15<00:00,  4.85s/it]
[LS] Doing inference...: 100%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½| 3/3 [00:15<00:00,  5.14s/it]
[LS] Restoring 42 faces...
[LS] 0%|          | 0/42 [00:00<?, ?it/s]
[LS] 5%|ï¿½ï¿½         | 2/42 [00:00<00:02, 17.46it/s]
[LS] 10%|ï¿½ï¿½         | 4/42 [00:00<00:02, 17.07it/s]
[LS] 14%|ï¿½ï¿½ï¿½ï¿½        | 6/42 [00:00<00:02, 17.69it/s]
[LS] 19%|ï¿½ï¿½ï¿½ï¿½        | 8/42 [00:00<00:01, 18.33it/s]
[LS] 24%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½       | 10/42 [00:00<00:01, 18.40it/s]
[LS] 29%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½       | 12/42 [00:00<00:01, 18.74it/s]
[LS] 33%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½      | 14/42 [00:00<00:01, 18.89it/s]
[LS] 38%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½      | 16/42 [00:00<00:01, 18.89it/s]
[LS] 43%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½     | 18/42 [00:00<00:01, 18.97it/s]
[LS] 48%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½     | 20/42 [00:01<00:01, 18.71it/s]
[LS] 52%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½    | 22/42 [00:01<00:01, 18.94it/s]
[LS] 57%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½    | 24/42 [00:01<00:00, 19.15it/s]
[LS] 62%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½   | 26/42 [00:01<00:00, 19.18it/s]
[LS] 67%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½   | 28/42 [00:01<00:00, 19.32it/s]
[LS] 71%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½  | 30/42 [00:01<00:00, 18.83it/s]
[LS] 76%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½  | 32/42 [00:01<00:00, 18.86it/s]
[LS] 81%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½  | 34/42 [00:01<00:00, 18.56it/s]
[LS] 86%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ | 36/42 [00:01<00:00, 18.33it/s]
[LS] 90%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ | 38/42 [00:02<00:00, 18.64it/s]
[LS] 95%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½| 40/42 [00:02<00:00, 18.71it/s]
[LS] 100%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½| 42/42 [00:02<00:00, 18.82it/s]
[LS] 100%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½| 42/42 [00:02<00:00, 18.69it/s]
