[MODEL] ÕıÔÚ¼ÓÔØ IndexTTS2 ÉùÑ§Ä£ĞÍ...
[MODEL] PyTorch CUDA¿ÉÓÃ: True
[MODEL] GPUÉè±¸: NVIDIA GeForce RTX 3080
[MODEL] CUDA°æ±¾: 12.8
>> GPT weights restored from: D:\ZhiMoAi_shuzi\_internal_tts\checkpoints\gpt.pth
GPT2InferenceModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From \U0001f449v4.50\U0001f448 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
>> Failed to load custom CUDA kernel for BigVGAN. Falling back to torch.
TypeError("unsupported operand type(s) for +: 'NoneType' and 'str'")
>> semantic_codec weights restored from: D:\ZhiMoAi_shuzi\_internal_tts\checkpoints\hf_cache\models--amphion--MaskGCT\snapshots\265c6cef07625665d0c28d2faafb1415562379dc\semantic_codec\model.safetensors
cfm loaded
length_regulator loaded
gpt_layer loaded
>> s2mel weights restored from: D:\ZhiMoAi_shuzi\_internal_tts\checkpoints\s2mel.pth
>> campplus_model weights restored from: D:\ZhiMoAi_shuzi\_internal_tts\checkpoints\hf_cache\models--funasr--campplus\snapshots\fb71fe990cbf6031ae6987a2d76fe64f94377b7e\campplus_cn_common.bin
Loading weights from nvidia/bigvgan_v2_22khz_80band_256x
Removing weight norm...
>> bigvgan weights restored from: nvidia/bigvgan_v2_22khz_80band_256x
>> TextNormalizer loaded
>> bpe model loaded from: D:\ZhiMoAi_shuzi\_internal_tts\checkpoints\bpe.model
[MODEL] Ä£ĞÍ¼ÓÔØÍê³É£¬ÕıÔÚÔ¤ÈÈÒıÇæ...
>> starting inference...
Use the specified emotion vector
The following generation flags are not valid and may be ignored: ['length_penalty']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.53.0. You should pass an instance of `Cache` instead, e.g. `past_key_values=DynamicCache.from_legacy_cache(past_key_values)`.
  0%|          | 0/25 [00:00<?, ?it/s]  4%|¨…         | 1/25 [00:00<00:03,  7.29it/s] 28%|¨€¨€¨‚       | 7/25 [00:00<00:00, 31.35it/s] 44%|¨€¨€¨€¨€¨…     | 11/25 [00:00<00:00, 24.68it/s] 56%|¨€¨€¨€¨€¨€¨„    | 14/25 [00:00<00:00, 22.74it/s] 68%|¨€¨€¨€¨€¨€¨€¨‚   | 17/25 [00:00<00:00, 21.66it/s] 80%|¨€¨€¨€¨€¨€¨€¨€¨€  | 20/25 [00:00<00:00, 20.92it/s] 92%|¨€¨€¨€¨€¨€¨€¨€¨€¨€¨‡| 23/25 [00:01<00:00, 20.44it/s]100%|¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€| 25/25 [00:01<00:00, 21.35it/s]
torch.Size([1, 19712])
>> gpt_gen_time: 0.91 seconds
>> gpt_forward_time: 0.01 seconds
>> s2mel_time: 1.18 seconds
>> bigvgan_time: 0.35 seconds
>> Total inference time: 3.42 seconds
>> Generated audio length: 0.89 seconds
>> RTF: 3.8225
>> wav file saved to: D:\ZhiMoAi_shuzi\unified_outputs\_warmup.wav
[MODEL] ÒıÇæÔ¤ÈÈÍê³É£¬Ê×´ÎºÏ³É½«Ö±½ÓÊä³ö
[MODEL] OK
[LS-SERVER] ³£×¤ÍÆÀí·şÎñ½«ÔÚÊ×´ÎÊÓÆµÉú³ÉÊ±ÀÁÆô¶¯
[TextExtractor] ºóÌ¨Ïß³ÌÒÑÆô¶¯
[TextExtractor] WebSocket Á¬½ÓÒÑÔÚºóÌ¨³õÊ¼»¯
[TextExtractor] WebSocket Á¬½Ó³É¹¦
>> starting inference...
Use the specified emotion vector
The following generation flags are not valid and may be ignored: ['length_penalty']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
  0%|          | 0/25 [00:00<?, ?it/s] 24%|¨€¨€¨…       | 6/25 [00:00<00:00, 47.57it/s] 44%|¨€¨€¨€¨€¨…     | 11/25 [00:00<00:00, 25.08it/s] 60%|¨€¨€¨€¨€¨€¨€    | 15/25 [00:00<00:00, 21.99it/s] 72%|¨€¨€¨€¨€¨€¨€¨€¨‡  | 18/25 [00:00<00:00, 20.64it/s] 84%|¨€¨€¨€¨€¨€¨€¨€¨€¨… | 21/25 [00:00<00:00, 19.81it/s] 96%|¨€¨€¨€¨€¨€¨€¨€¨€¨€¨„| 24/25 [00:01<00:00, 19.19it/s]100%|¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€| 25/25 [00:01<00:00, 21.21it/s]
torch.Size([1, 48384])
>> gpt_gen_time: 1.43 seconds
>> gpt_forward_time: 0.01 seconds
>> s2mel_time: 1.18 seconds
>> bigvgan_time: 0.14 seconds
>> Total inference time: 3.32 seconds
>> Generated audio length: 2.19 seconds
>> RTF: 1.5147
>> wav file saved to: D:\ZhiMoAi_shuzi\unified_outputs\tts_1771786253.wav
[GPU] TTS Ä£ĞÍÒÑÔİÊ±ÒÆµ½ CPU£¬ÏÔ´æÒÑÊÍ·Å
[LS-SERVER] ·şÎñ½ø³Ì²»´æÔÚ»òÒÑÍË³ö£¬ÕıÔÚÖØÆô...
[LS-SERVER] ÕıÔÚÆô¶¯³£×¤ÍÆÀí·şÎñ£¨¼ÓÔØÄ£ĞÍÖĞ£©...
[LS-SERVER] [SERVER] Loading models (dtype=torch.float16)...
[LS-SERVER] [SERVER] Audio encoder loaded
[LS-SERVER] [SERVER] VAE loaded
[LS-SERVER] [SERVER] UNet loaded
[LS-SERVER] [SERVER] Pipeline ready on CUDA
[LS-SERVER] __READY__
[LS-SERVER] âœ… æ¨ç†æœåŠ¡å°±ç»ªï¼Œæ¨¡å‹å·²å¸¸é©»GPUæ˜¾å­˜
[LS] Input video path: D:\ZhiMoAi_shuzi\unified_outputs\in_v_1771786275.mp4
[LS] Input audio path: D:\ZhiMoAi_shuzi\unified_outputs\in_a_1771786275.wav
[LS] Loaded checkpoint path: (persistent)
[LS] Initial seed: 1247
[LS] video in 25 FPS, audio idx in 50FPS
[LS] Affine transforming 56 faces...
[LS] 0%|          | 0/56 [00:00<?, ?it/s]
[LS] 2%|ï¿½ï¿½         | 1/56 [00:06<05:48,  6.33s/it]
[LS] 4%|ï¿½ï¿½         | 2/56 [00:09<04:06,  4.56s/it]
[LS] 5%|ï¿½ï¿½         | 3/56 [00:09<02:13,  2.52s/it]
[LS] 7%|ï¿½ï¿½         | 4/56 [00:09<01:21,  1.58s/it]
[LS] 11%|ï¿½ï¿½         | 6/56 [00:09<00:38,  1.29it/s]
[LS] 14%|ï¿½ï¿½ï¿½ï¿½        | 8/56 [00:10<00:22,  2.13it/s]
[LS] 18%|ï¿½ï¿½ï¿½ï¿½        | 10/56 [00:10<00:14,  3.17it/s]
[LS] 21%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½       | 12/56 [00:10<00:10,  4.39it/s]
[LS] 25%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½       | 14/56 [00:10<00:07,  5.78it/s]
[LS] 29%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½       | 16/56 [00:10<00:05,  7.27it/s]
[LS] 32%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½      | 18/56 [00:10<00:04,  8.72it/s]
[LS] 36%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½      | 20/56 [00:10<00:03, 10.03it/s]
[LS] 39%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½      | 22/56 [00:11<00:03, 11.17it/s]
[LS] 43%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½     | 24/56 [00:11<00:02, 12.12it/s]
[LS] 46%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½     | 26/56 [00:11<00:02, 12.89it/s]
[LS] 50%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½     | 28/56 [00:11<00:02, 13.43it/s]
[LS] 54%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½    | 30/56 [00:11<00:01, 13.85it/s]
[LS] 57%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½    | 32/56 [00:11<00:01, 14.25it/s]
[LS] 61%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½    | 34/56 [00:11<00:01, 14.45it/s]
[LS] 64%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½   | 36/56 [00:11<00:01, 14.63it/s]
[LS] 68%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½   | 38/56 [00:12<00:01, 14.78it/s]
[LS] 71%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½  | 40/56 [00:12<00:01, 14.80it/s]
[LS] 75%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½  | 42/56 [00:12<00:00, 14.84it/s]
[LS] 79%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½  | 44/56 [00:12<00:00, 14.92it/s]
[LS] 82%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ | 46/56 [00:12<00:00, 15.02it/s]
[LS] 86%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ | 48/56 [00:12<00:00, 15.34it/s]
[LS] 89%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ | 50/56 [00:12<00:00, 15.14it/s]
[LS] 93%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½| 52/56 [00:13<00:00, 15.21it/s]
[LS] 96%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½| 54/56 [00:13<00:00, 15.17it/s]
[LS] 100%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½| 56/56 [00:13<00:00, 15.15it/s]
[LS] 100%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½| 56/56 [00:13<00:00,  4.21it/s]
[LS] Doing inference...:   0%|          | 0/4 [00:00<?, ?it/s]D:\ZhiMoAi_shuzi\_internal_sync\latents_env\Lib\site-packages\diffusers\models\attention_processor.py:3286: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\actions-runner\_work\pytorch\pytorch\builder\windows\pytorch\aten\src\ATen\native\transformers\cuda\sdp_utils.cpp:555.)
[LS] hidden_states = F.scaled_dot_product_attention(
[LS] Sample frames: 16:   0%|          | 0/12 [00:00<?, ?it/s][A
[LS] Sample frames: 16:   8%|ï¿½ï¿½         | 1/12 [00:01<00:17,  1.58s/it][A
[LS] Sample frames: 16:  17%|ï¿½ï¿½ï¿½ï¿½        | 2/12 [00:01<00:08,  1.25it/s][A
[LS] Sample frames: 16:  25%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½       | 3/12 [00:02<00:04,  1.80it/s][A
[LS] Sample frames: 16:  33%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½      | 4/12 [00:02<00:03,  2.29it/s][A
[LS] Sample frames: 16:  42%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½     | 5/12 [00:02<00:02,  2.68it/s][A
[LS] Sample frames: 16:  50%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½     | 6/12 [00:02<00:02,  3.00it/s][A
[LS] Sample frames: 16:  58%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½    | 7/12 [00:03<00:01,  3.24it/s][A
[LS] Sample frames: 16:  67%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½   | 8/12 [00:03<00:01,  3.42it/s][A
[LS] Sample frames: 16:  75%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½  | 9/12 [00:03<00:00,  3.55it/s][A
[LS] Sample frames: 16:  83%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ | 10/12 [00:03<00:00,  3.65it/s][A
[LS] Sample frames: 16:  92%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½| 11/12 [00:04<00:00,  3.73it/s][A
[LS] Sample frames: 16: 100%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½| 12/12 [00:04<00:00,  3.77it/s][A
[LS] Sample frames: 16: 100%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½| 12/12 [00:04<00:00,  2.72it/s]
[LS] Doing inference...:  25%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½       | 1/4 [00:08<00:24,  8.20s/it]
[LS] Sample frames: 16:   0%|          | 0/12 [00:00<?, ?it/s][A
[LS] Sample frames: 16:   8%|ï¿½ï¿½         | 1/12 [00:00<00:04,  2.41it/s][A
[LS] Sample frames: 16:  17%|ï¿½ï¿½ï¿½ï¿½        | 2/12 [00:00<00:03,  3.11it/s][A
[LS] Sample frames: 16:  25%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½       | 3/12 [00:00<00:02,  3.44it/s][A
[LS] Sample frames: 16:  33%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½      | 4/12 [00:01<00:02,  3.60it/s][A
[LS] Sample frames: 16:  42%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½     | 5/12 [00:01<00:01,  3.70it/s][A
[LS] Sample frames: 16:  50%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½     | 6/12 [00:01<00:01,  3.76it/s][A
[LS] Sample frames: 16:  58%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½    | 7/12 [00:01<00:01,  3.79it/s][A
[LS] Sample frames: 16:  67%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½   | 8/12 [00:02<00:01,  3.80it/s][A
[LS] Sample frames: 16:  75%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½  | 9/12 [00:02<00:00,  3.83it/s][A
[LS] Sample frames: 16:  83%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ | 10/12 [00:02<00:00,  3.82it/s][A
[LS] Sample frames: 16:  92%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½| 11/12 [00:02<00:00,  3.83it/s][A
[LS] Sample frames: 16: 100%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½| 12/12 [00:03<00:00,  3.82it/s][A
[LS] Sample frames: 16: 100%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½| 12/12 [00:03<00:00,  3.68it/s]
[LS] Doing inference...:  50%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½     | 2/4 [00:12<00:11,  5.65s/it]
[LS] Sample frames: 16:   0%|          | 0/12 [00:00<?, ?it/s][A
[LS] Sample frames: 16:   8%|ï¿½ï¿½         | 1/12 [00:00<00:04,  2.39it/s][A
[LS] Sample frames: 16:  17%|ï¿½ï¿½ï¿½ï¿½        | 2/12 [00:00<00:03,  3.08it/s][A
[LS] Sample frames: 16:  25%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½       | 3/12 [00:00<00:02,  3.42it/s][A
[LS] Sample frames: 16:  33%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½      | 4/12 [00:01<00:02,  3.59it/s][A
[LS] Sample frames: 16:  42%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½     | 5/12 [00:01<00:01,  3.67it/s][A
[LS] Sample frames: 16:  50%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½     | 6/12 [00:01<00:01,  3.76it/s][A
[LS] Sample frames: 16:  58%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½    | 7/12 [00:01<00:01,  3.79it/s][A
[LS] Sample frames: 16:  67%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½   | 8/12 [00:02<00:01,  3.83it/s][A
[LS] Sample frames: 16:  75%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½  | 9/12 [00:02<00:00,  3.83it/s][A
[LS] Sample frames: 16:  83%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ | 10/12 [00:02<00:00,  3.85it/s][A
[LS] Sample frames: 16:  92%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½| 11/12 [00:02<00:00,  3.84it/s][A
[LS] Sample frames: 16: 100%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½| 12/12 [00:03<00:00,  3.86it/s][A
[LS] Sample frames: 16: 100%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½| 12/12 [00:03<00:00,  3.69it/s]
[LS] Doing inference...:  75%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½  | 3/4 [00:15<00:04,  4.83s/it]
[LS] Sample frames: 16:   0%|          | 0/12 [00:00<?, ?it/s][A
[LS] Sample frames: 16:   8%|ï¿½ï¿½         | 1/12 [00:00<00:09,  1.14it/s][A
[LS] Sample frames: 16:  17%|ï¿½ï¿½ï¿½ï¿½        | 2/12 [00:01<00:04,  2.27it/s][A
[LS] Sample frames: 16:  25%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½       | 3/12 [00:01<00:02,  3.30it/s][A
[LS] Sample frames: 16:  33%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½      | 4/12 [00:01<00:01,  4.20it/s][A
[LS] Sample frames: 16:  42%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½     | 5/12 [00:01<00:01,  4.92it/s][A
[LS] Sample frames: 16:  50%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½     | 6/12 [00:01<00:01,  5.52it/s][A
[LS] Sample frames: 16:  58%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½    | 7/12 [00:01<00:00,  6.00it/s][A
[LS] Sample frames: 16:  67%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½   | 8/12 [00:01<00:00,  6.31it/s][A
[LS] Sample frames: 16:  75%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½  | 9/12 [00:01<00:00,  6.57it/s][A
[LS] Sample frames: 16:  83%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ | 10/12 [00:02<00:00,  6.77it/s][A
[LS] Sample frames: 16:  92%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½| 11/12 [00:02<00:00,  6.88it/s][A
[LS] Sample frames: 16: 100%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½| 12/12 [00:02<00:00,  6.98it/s][A
[LS] Sample frames: 16: 100%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½| 12/12 [00:02<00:00,  5.00it/s]
[LS] Doing inference...: 100%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½| 4/4 [00:20<00:00,  4.63s/it]
[LS] Doing inference...: 100%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½| 4/4 [00:20<00:00,  5.06s/it]
[LS] Restoring 56 faces...
[LS] 0%|          | 0/56 [00:00<?, ?it/s]
[LS] 4%|ï¿½ï¿½         | 2/56 [00:00<00:02, 18.43it/s]
[LS] 9%|ï¿½ï¿½         | 5/56 [00:00<00:02, 19.69it/s]
[LS] 12%|ï¿½ï¿½ï¿½ï¿½        | 7/56 [00:00<00:02, 19.75it/s]
[LS] 16%|ï¿½ï¿½ï¿½ï¿½        | 9/56 [00:00<00:02, 19.82it/s]
[LS] 20%|ï¿½ï¿½ï¿½ï¿½        | 11/56 [00:00<00:02, 19.41it/s]
[LS] 23%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½       | 13/56 [00:00<00:02, 19.38it/s]
[LS] 29%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½       | 16/56 [00:00<00:02, 19.81it/s]
[LS] 34%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½      | 19/56 [00:00<00:01, 20.10it/s]
[LS] 39%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½      | 22/56 [00:01<00:01, 20.22it/s]
[LS] 45%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½     | 25/56 [00:01<00:01, 19.77it/s]
[LS] 48%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½     | 27/56 [00:01<00:01, 19.47it/s]
[LS] 52%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½    | 29/56 [00:01<00:01, 19.29it/s]
[LS] 55%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½    | 31/56 [00:01<00:01, 18.91it/s]
[LS] 59%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½    | 33/56 [00:01<00:01, 19.18it/s]
[LS] 64%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½   | 36/56 [00:01<00:01, 19.56it/s]
[LS] 70%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½   | 39/56 [00:01<00:00, 19.83it/s]
[LS] 73%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½  | 41/56 [00:02<00:00, 19.82it/s]
[LS] 79%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½  | 44/56 [00:02<00:00, 19.99it/s]
[LS] 82%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ | 46/56 [00:02<00:00, 19.89it/s]
[LS] 86%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ | 48/56 [00:02<00:00, 19.39it/s]
[LS] 91%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ | 51/56 [00:02<00:00, 19.66it/s]
[LS] 96%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½| 54/56 [00:02<00:00, 19.91it/s]
[LS] 100%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½| 56/56 [00:02<00:00, 19.70it/s]
[LS] __DONE__:D:\ZhiMoAi_shuzi\unified_outputs\lipsync_1771786275.mp4
[LS] âœ… é€šè¿‡å¸¸é©»æœåŠ¡å®Œæˆæ¨ç†
[GPU] TTS Ä£ĞÍÒÑ»Ö¸´µ½ GPU
