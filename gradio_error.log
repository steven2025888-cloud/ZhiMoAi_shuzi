[MODEL] 正在加载 IndexTTS2 声学模型...
>> GPT weights restored from: D:\ZhiMoAi_shuzi\IndexTTS2-SonicVale\checkpoints\gpt.pth
GPT2InferenceModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From \U0001f449v4.50\U0001f448 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
>> Failed to load custom CUDA kernel for BigVGAN. Falling back to torch.
TypeError("unsupported operand type(s) for +: 'NoneType' and 'str'")
>> semantic_codec weights restored from: D:\ZhiMoAi_shuzi\IndexTTS2-SonicVale\checkpoints\hf_cache\models--amphion--MaskGCT\snapshots\265c6cef07625665d0c28d2faafb1415562379dc\semantic_codec\model.safetensors
cfm loaded
length_regulator loaded
gpt_layer loaded
>> s2mel weights restored from: D:\ZhiMoAi_shuzi\IndexTTS2-SonicVale\checkpoints\s2mel.pth
>> campplus_model weights restored from: D:\ZhiMoAi_shuzi\IndexTTS2-SonicVale\checkpoints\hf_cache\models--funasr--campplus\snapshots\fb71fe990cbf6031ae6987a2d76fe64f94377b7e\campplus_cn_common.bin
Loading weights from nvidia/bigvgan_v2_22khz_80band_256x
Removing weight norm...
>> bigvgan weights restored from: nvidia/bigvgan_v2_22khz_80band_256x
>> TextNormalizer loaded
>> bpe model loaded from: D:\ZhiMoAi_shuzi\IndexTTS2-SonicVale\checkpoints\bpe.model
[MODEL] 模型加载完成，正在预热引擎...
>> starting inference...
Use the specified emotion vector
The following generation flags are not valid and may be ignored: ['length_penalty']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.53.0. You should pass an instance of `Cache` instead, e.g. `past_key_values=DynamicCache.from_legacy_cache(past_key_values)`.
  0%|          | 0/25 [00:00<?, ?it/s]  4%|         | 1/25 [00:00<00:02,  9.26it/s] 28%|       | 7/25 [00:00<00:00, 35.90it/s] 44%|     | 11/25 [00:00<00:00, 27.27it/s] 56%|    | 14/25 [00:00<00:00, 24.98it/s] 68%|   | 17/25 [00:00<00:00, 23.76it/s] 80%|  | 20/25 [00:00<00:00, 22.93it/s] 92%|| 23/25 [00:00<00:00, 22.45it/s]100%|| 25/25 [00:01<00:00, 23.56it/s]
torch.Size([1, 20480])
>> gpt_gen_time: 0.83 seconds
>> gpt_forward_time: 0.01 seconds
>> s2mel_time: 1.07 seconds
>> bigvgan_time: 0.25 seconds
>> Total inference time: 3.18 seconds
>> Generated audio length: 0.93 seconds
>> RTF: 3.4275
>> wav file saved to: D:\ZhiMoAi_shuzi\unified_outputs\_warmup.wav
[MODEL] 引擎预热完成，首次合成将直接输出
[MODEL] OK
[WARMUP] 正在预热 LatentSync 引擎...
[WARMUP] LatentSync 预热返回非零码: 1
[WARMUP] stderr: Traceback (most recent call last):
  File "<string>", line 1, in <module>
ImportError: cannot import name 'load_model' from 'latentsync.utils.util' (D:\ZhiMoAi_shuzi\LatentSync\latentsync\utils\util.py)

[TextExtractor] 后台线程已启动
[TextExtractor] WebSocket 连接已在后台初始化
[TextExtractor] 正在连接 wss://api.zhimengai.xyz/dsp
[TextExtractor] WebSocket 连接成功
[TextExtractor] 已发送注册消息
[TextExtractor] 收到注册响应: {"type":"connected","fd":76}
[TextExtractor] 收到消息: {"type":"registered","key":"2RFH-MOFU-XVTZ-N79P"}
[TextExtractor] 已发送提取请求: {"type":"url","url":"4.12 06/20 x@s.Rx vfO:/ 还在问场景...
[TextExtractor] 收到消息: {"type":"ack","msg":"\u5df2\u63d0\u4ea4"}
[TextExtractor] 收到消息: {"type":"result","content":"hello,兄弟们来了，有我上次说要搭建那个实景的红包直播间啊，给大家一惊到底。\n有人说哎呀，你不露脸不行啊，露手卖不出去。\n非也啊，我以前带那个品知道吧啊。\n呃，我的一个同行啊，我的偶像，他就是全程只卖只只只露一个手，一天几千单，比我卖的好多了啊，去学习一下，不要只盯着我啊，对不对啊？\n人家就露个手啊啊，一天几千单，我都是一个小虾米...
>> starting inference...
Use the specified emotion vector
The following generation flags are not valid and may be ignored: ['length_penalty']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
  0%|          | 0/25 [00:00<?, ?it/s] 16%|        | 4/25 [00:00<00:00, 37.53it/s] 32%|      | 8/25 [00:00<00:00, 19.80it/s] 44%|     | 11/25 [00:00<00:00, 15.55it/s] 52%|    | 13/25 [00:00<00:00, 14.21it/s] 60%|    | 15/25 [00:00<00:00, 13.10it/s] 68%|   | 17/25 [00:01<00:00, 12.57it/s] 76%|  | 19/25 [00:01<00:00, 12.29it/s] 84%| | 21/25 [00:01<00:00, 12.10it/s] 92%|| 23/25 [00:01<00:00, 11.81it/s]100%|| 25/25 [00:01<00:00, 11.58it/s]100%|| 25/25 [00:01<00:00, 13.37it/s]
torch.Size([1, 221440])
Use the specified emotion vector
The following generation flags are not valid and may be ignored: ['length_penalty']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
  0%|          | 0/25 [00:00<?, ?it/s]  4%|         | 1/25 [00:00<00:04,  5.86it/s] 24%|       | 6/25 [00:00<00:00, 22.86it/s] 36%|      | 9/25 [00:00<00:01, 15.73it/s] 44%|     | 11/25 [00:00<00:00, 14.09it/s] 52%|    | 13/25 [00:00<00:00, 13.10it/s] 60%|    | 15/25 [00:01<00:00, 12.47it/s] 68%|   | 17/25 [00:01<00:00, 11.95it/s] 76%|  | 19/25 [00:01<00:00, 11.71it/s] 84%| | 21/25 [00:01<00:00, 11.68it/s] 92%|| 23/25 [00:01<00:00, 11.42it/s]100%|| 25/25 [00:02<00:00, 11.30it/s]100%|| 25/25 [00:02<00:00, 12.46it/s]
torch.Size([1, 217344])
Use the specified emotion vector
The following generation flags are not valid and may be ignored: ['length_penalty']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
  0%|          | 0/25 [00:00<?, ?it/s] 20%|        | 5/25 [00:00<00:00, 41.68it/s] 40%|      | 10/25 [00:00<00:00, 16.25it/s] 52%|    | 13/25 [00:00<00:00, 14.27it/s] 60%|    | 15/25 [00:00<00:00, 13.46it/s] 68%|   | 17/25 [00:01<00:00, 13.02it/s] 76%|  | 19/25 [00:01<00:00, 12.57it/s] 84%| | 21/25 [00:01<00:00, 12.13it/s] 92%|| 23/25 [00:01<00:00, 11.98it/s]100%|| 25/25 [00:01<00:00, 11.93it/s]100%|| 25/25 [00:01<00:00, 13.45it/s]
torch.Size([1, 218624])
Use the specified emotion vector
The following generation flags are not valid and may be ignored: ['length_penalty']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
