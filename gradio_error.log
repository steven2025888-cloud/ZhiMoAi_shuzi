[MODEL] ÕıÔÚ¼ÓÔØ IndexTTS2 ÉùÑ§Ä£ĞÍ...
[MODEL] PyTorch CUDA¿ÉÓÃ: True
[MODEL] GPUÉè±¸: NVIDIA GeForce RTX 3080
[MODEL] CUDA°æ±¾: 12.8
>> GPT weights restored from: D:\ZhiMoAi_shuzi\_internal_tts\checkpoints\gpt.pth
GPT2InferenceModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From \U0001f449v4.50\U0001f448 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
>> Failed to load custom CUDA kernel for BigVGAN. Falling back to torch.
TypeError("unsupported operand type(s) for +: 'NoneType' and 'str'")
>> semantic_codec weights restored from: D:\ZhiMoAi_shuzi\_internal_tts\checkpoints\hf_cache\models--amphion--MaskGCT\snapshots\265c6cef07625665d0c28d2faafb1415562379dc\semantic_codec\model.safetensors
cfm loaded
length_regulator loaded
gpt_layer loaded
>> s2mel weights restored from: D:\ZhiMoAi_shuzi\_internal_tts\checkpoints\s2mel.pth
>> campplus_model weights restored from: D:\ZhiMoAi_shuzi\_internal_tts\checkpoints\hf_cache\models--funasr--campplus\snapshots\fb71fe990cbf6031ae6987a2d76fe64f94377b7e\campplus_cn_common.bin
Loading weights from nvidia/bigvgan_v2_22khz_80band_256x
Removing weight norm...
>> bigvgan weights restored from: nvidia/bigvgan_v2_22khz_80band_256x
>> TextNormalizer loaded
>> bpe model loaded from: D:\ZhiMoAi_shuzi\_internal_tts\checkpoints\bpe.model
[MODEL] Ä£ĞÍ¼ÓÔØÍê³É£¬ÕıÔÚÔ¤ÈÈÒıÇæ...
>> starting inference...
Use the specified emotion vector
The following generation flags are not valid and may be ignored: ['length_penalty']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.53.0. You should pass an instance of `Cache` instead, e.g. `past_key_values=DynamicCache.from_legacy_cache(past_key_values)`.
  0%|          | 0/25 [00:00<?, ?it/s]  4%|¨…         | 1/25 [00:00<00:03,  7.76it/s] 28%|¨€¨€¨‚       | 7/25 [00:00<00:00, 31.70it/s] 44%|¨€¨€¨€¨€¨…     | 11/25 [00:00<00:00, 24.93it/s] 56%|¨€¨€¨€¨€¨€¨„    | 14/25 [00:00<00:00, 23.09it/s] 68%|¨€¨€¨€¨€¨€¨€¨‚   | 17/25 [00:00<00:00, 22.12it/s] 80%|¨€¨€¨€¨€¨€¨€¨€¨€  | 20/25 [00:00<00:00, 21.42it/s] 92%|¨€¨€¨€¨€¨€¨€¨€¨€¨€¨‡| 23/25 [00:01<00:00, 20.91it/s]100%|¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€| 25/25 [00:01<00:00, 21.77it/s]
torch.Size([1, 14848])
>> gpt_gen_time: 0.82 seconds
>> gpt_forward_time: 0.01 seconds
>> s2mel_time: 1.16 seconds
>> bigvgan_time: 0.30 seconds
>> Total inference time: 3.30 seconds
>> Generated audio length: 0.67 seconds
>> RTF: 4.8967
>> wav file saved to: D:\ZhiMoAi_shuzi\unified_outputs\_warmup.wav
[MODEL] ÒıÇæÔ¤ÈÈÍê³É£¬Ê×´ÎºÏ³É½«Ö±½ÓÊä³ö
[MODEL] OK
[LS-SERVER] ³£×¤ÍÆÀí·şÎñ½«ÔÚÊ×´ÎÊÓÆµÉú³ÉÊ±ÀÁÆô¶¯
[TextExtractor] ºóÌ¨Ïß³ÌÒÑÆô¶¯
[TextExtractor] WebSocket Á¬½ÓÒÑÔÚºóÌ¨³õÊ¼»¯
[TextExtractor] WebSocket Á¬½Ó³É¹¦
>> starting inference...
Use the specified emotion vector
The following generation flags are not valid and may be ignored: ['length_penalty']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
  0%|          | 0/25 [00:00<?, ?it/s] 24%|¨€¨€¨…       | 6/25 [00:00<00:00, 45.04it/s] 44%|¨€¨€¨€¨€¨…     | 11/25 [00:00<00:00, 25.08it/s] 56%|¨€¨€¨€¨€¨€¨„    | 14/25 [00:00<00:00, 22.59it/s] 68%|¨€¨€¨€¨€¨€¨€¨‚   | 17/25 [00:00<00:00, 21.13it/s] 80%|¨€¨€¨€¨€¨€¨€¨€¨€  | 20/25 [00:00<00:00, 20.15it/s] 92%|¨€¨€¨€¨€¨€¨€¨€¨€¨€¨‡| 23/25 [00:01<00:00, 19.35it/s]100%|¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€| 25/25 [00:01<00:00, 19.17it/s]100%|¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€| 25/25 [00:01<00:00, 21.35it/s]
torch.Size([1, 49664])
>> gpt_gen_time: 1.46 seconds
>> gpt_forward_time: 0.01 seconds
>> s2mel_time: 1.18 seconds
>> bigvgan_time: 0.14 seconds
>> Total inference time: 3.32 seconds
>> Generated audio length: 2.25 seconds
>> RTF: 1.4739
>> wav file saved to: D:\ZhiMoAi_shuzi\unified_outputs\tts_1771912319.wav
[GPU] TTS Ä£ĞÍÒÑÍêÈ«Ğ¶ÔØ£¨GPU + RAM ¾ùÒÑÊÍ·Å£©
[LS-SERVER] ·şÎñ½ø³Ì²»´æÔÚ»òÒÑÍË³ö£¬ÕıÔÚÖØÆô...
[LS-SERVER] ÕıÔÚÆô¶¯³£×¤ÍÆÀí·şÎñ£¨¼ÓÔØÄ£ĞÍÖĞ£©...
[LS-SERVER] [SERVER] Loading models (dtype=torch.float16)...
[LS-SERVER] [SERVER] Audio encoder loaded
[LS-SERVER] [SERVER] VAE loaded
[LS-SERVER] [SERVER] UNet loaded
[LS-SERVER] [SERVER] Pipeline ready on CUDA
[LS-SERVER] __READY__
[LS-SERVER] âœ… æ¨ç†æœåŠ¡å°±ç»ªï¼Œæ¨¡å‹å·²å¸¸é©»GPUæ˜¾å­˜
[LS] Input video path: D:\ZhiMoAi_shuzi\unified_outputs\in_v_1771912329.mp4
[LS] Input audio path: D:\ZhiMoAi_shuzi\unified_outputs\in_a_1771912329.wav
[LS] Loaded checkpoint path: (persistent)
[LS] Initial seed: 1247
[LS] video in 25 FPS, audio idx in 50FPS
[LS] Affine transforming 58 faces...
[LS] 0%|          | 0/58 [00:00<?, ?it/s]
[LS] 2%|ï¿½ï¿½         | 1/58 [00:09<08:38,  9.10s/it]
[LS] 3%|ï¿½ï¿½         | 2/58 [00:14<06:13,  6.67s/it]
[LS] 5%|ï¿½ï¿½         | 3/58 [00:14<03:24,  3.72s/it]
[LS] 9%|ï¿½ï¿½         | 5/58 [00:14<01:27,  1.65s/it]
[LS] 12%|ï¿½ï¿½ï¿½ï¿½        | 7/58 [00:14<00:47,  1.06it/s]
[LS] 16%|ï¿½ï¿½ï¿½ï¿½        | 9/58 [00:14<00:29,  1.68it/s]
[LS] 19%|ï¿½ï¿½ï¿½ï¿½        | 11/58 [00:14<00:18,  2.47it/s]
[LS] 22%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½       | 13/58 [00:14<00:12,  3.47it/s]
[LS] 26%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½       | 15/58 [00:14<00:09,  4.70it/s]
[LS] 29%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½       | 17/58 [00:15<00:06,  6.10it/s]
[LS] 33%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½      | 19/58 [00:15<00:05,  7.58it/s]
[LS] 36%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½      | 21/58 [00:15<00:04,  9.04it/s]
[LS] 40%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½      | 23/58 [00:15<00:03, 10.50it/s]
[LS] 43%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½     | 25/58 [00:15<00:02, 11.80it/s]
[LS] 47%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½     | 27/58 [00:15<00:02, 12.93it/s]
[LS] 50%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½     | 29/58 [00:15<00:02, 13.81it/s]
[LS] 53%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½    | 31/58 [00:15<00:01, 14.56it/s]
[LS] 57%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½    | 33/58 [00:16<00:01, 15.42it/s]
[LS] 60%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½    | 35/58 [00:16<00:01, 15.97it/s]
[LS] 64%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½   | 37/58 [00:16<00:01, 16.46it/s]
[LS] 67%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½   | 39/58 [00:16<00:01, 16.79it/s]
[LS] 71%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½   | 41/58 [00:16<00:01, 16.92it/s]
[LS] 74%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½  | 43/58 [00:16<00:00, 16.93it/s]
[LS] 78%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½  | 45/58 [00:16<00:00, 16.96it/s]
[LS] 81%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½  | 47/58 [00:16<00:00, 17.06it/s]
[LS] 84%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ | 49/58 [00:17<00:00, 16.95it/s]
[LS] 88%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ | 51/58 [00:17<00:00, 17.08it/s]
[LS] 91%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½| 53/58 [00:17<00:00, 16.95it/s]
[LS] 95%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½| 55/58 [00:17<00:00, 17.07it/s]
[LS] 98%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½| 57/58 [00:17<00:00, 17.20it/s]
[LS] 100%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½| 58/58 [00:17<00:00,  3.31it/s]
[LS] Doing inference...:   0%|          | 0/4 [00:00<?, ?it/s]D:\ZhiMoAi_shuzi\_internal_sync\latents_env\Lib\site-packages\diffusers\models\attention_processor.py:3286: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\actions-runner\_work\pytorch\pytorch\builder\windows\pytorch\aten\src\ATen\native\transformers\cuda\sdp_utils.cpp:555.)
[LS] hidden_states = F.scaled_dot_product_attention(
[LS] Sample frames: 16:   0%|          | 0/12 [00:00<?, ?it/s][A
[LS] Sample frames: 16:   8%|ï¿½ï¿½         | 1/12 [00:01<00:15,  1.37s/it][A
[LS] Sample frames: 16:  17%|ï¿½ï¿½ï¿½ï¿½        | 2/12 [00:01<00:06,  1.43it/s][A
[LS] Sample frames: 16:  25%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½       | 3/12 [00:01<00:04,  2.05it/s][A
[LS] Sample frames: 16:  33%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½      | 4/12 [00:02<00:03,  2.58it/s][A
[LS] Sample frames: 16:  42%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½     | 5/12 [00:02<00:02,  3.00it/s][A
[LS] Sample frames: 16:  50%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½     | 6/12 [00:02<00:01,  3.32it/s][A
[LS] Sample frames: 16:  58%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½    | 7/12 [00:02<00:01,  3.65it/s][A
[LS] Sample frames: 16:  67%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½   | 8/12 [00:02<00:01,  3.86it/s][A
[LS] Sample frames: 16:  75%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½  | 9/12 [00:03<00:00,  4.06it/s][A
[LS] Sample frames: 16:  83%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ | 10/12 [00:03<00:00,  4.17it/s][A
[LS] Sample frames: 16:  92%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½| 11/12 [00:03<00:00,  4.25it/s][A
[LS] Sample frames: 16: 100%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½| 12/12 [00:03<00:00,  4.32it/s][A
[LS] Sample frames: 16: 100%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½| 12/12 [00:03<00:00,  3.09it/s]
[LS] Doing inference...:  25%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½       | 1/4 [00:07<00:21,  7.20s/it]
[LS] Sample frames: 16:   0%|          | 0/12 [00:00<?, ?it/s][A
[LS] Sample frames: 16:   8%|ï¿½ï¿½         | 1/12 [00:00<00:03,  2.83it/s][A
[LS] Sample frames: 16:  17%|ï¿½ï¿½ï¿½ï¿½        | 2/12 [00:00<00:02,  3.59it/s][A
[LS] Sample frames: 16:  25%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½       | 3/12 [00:00<00:02,  3.94it/s][A
[LS] Sample frames: 16:  33%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½      | 4/12 [00:01<00:01,  4.17it/s][A
[LS] Sample frames: 16:  42%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½     | 5/12 [00:01<00:01,  4.24it/s][A
[LS] Sample frames: 16:  50%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½     | 6/12 [00:01<00:01,  4.32it/s][A
[LS] Sample frames: 16:  58%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½    | 7/12 [00:01<00:01,  4.37it/s][A
[LS] Sample frames: 16:  67%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½   | 8/12 [00:01<00:00,  4.42it/s][A
[LS] Sample frames: 16:  75%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½  | 9/12 [00:02<00:00,  4.44it/s][A
[LS] Sample frames: 16:  83%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ | 10/12 [00:02<00:00,  4.46it/s][A
[LS] Sample frames: 16:  92%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½| 11/12 [00:02<00:00,  4.46it/s][A
[LS] Sample frames: 16: 100%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½| 12/12 [00:02<00:00,  4.44it/s][A
[LS] Sample frames: 16: 100%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½| 12/12 [00:02<00:00,  4.26it/s]
[LS] Doing inference...:  50%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½     | 2/4 [00:10<00:09,  4.93s/it]
[LS] Sample frames: 16:   0%|          | 0/12 [00:00<?, ?it/s][A
[LS] Sample frames: 16:   8%|ï¿½ï¿½         | 1/12 [00:00<00:04,  2.62it/s][A
[LS] Sample frames: 16:  17%|ï¿½ï¿½ï¿½ï¿½        | 2/12 [00:00<00:03,  3.33it/s][A
[LS] Sample frames: 16:  25%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½       | 3/12 [00:00<00:02,  3.55it/s][A
[LS] Sample frames: 16:  33%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½      | 4/12 [00:01<00:02,  3.75it/s][A
[LS] Sample frames: 16:  42%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½     | 5/12 [00:01<00:01,  3.87it/s][A
[LS] Sample frames: 16:  50%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½     | 6/12 [00:01<00:01,  3.88it/s][A
[LS] Sample frames: 16:  58%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½    | 7/12 [00:01<00:01,  3.95it/s][A
[LS] Sample frames: 16:  67%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½   | 8/12 [00:02<00:01,  3.97it/s][A
[LS] Sample frames: 16:  75%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½  | 9/12 [00:02<00:00,  4.09it/s][A
[LS] Sample frames: 16:  83%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ | 10/12 [00:02<00:00,  4.17it/s][A
[LS] Sample frames: 16:  92%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½| 11/12 [00:02<00:00,  4.23it/s][A
[LS] Sample frames: 16: 100%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½| 12/12 [00:03<00:00,  4.29it/s][A
[LS] Sample frames: 16: 100%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½| 12/12 [00:03<00:00,  3.96it/s]
[LS] Doing inference...:  75%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½  | 3/4 [00:14<00:04,  4.35s/it]
[LS] Sample frames: 16:   0%|          | 0/12 [00:00<?, ?it/s][A
[LS] Sample frames: 16:   8%|ï¿½ï¿½         | 1/12 [00:01<00:11,  1.09s/it][A
[LS] Sample frames: 16:  17%|ï¿½ï¿½ï¿½ï¿½        | 2/12 [00:01<00:05,  1.84it/s][A
[LS] Sample frames: 16:  25%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½       | 3/12 [00:01<00:03,  2.74it/s][A
[LS] Sample frames: 16:  33%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½      | 4/12 [00:01<00:02,  3.51it/s][A
[LS] Sample frames: 16:  42%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½     | 5/12 [00:01<00:01,  4.19it/s][A
[LS] Sample frames: 16:  50%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½     | 6/12 [00:01<00:01,  4.77it/s][A
[LS] Sample frames: 16:  58%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½    | 7/12 [00:02<00:00,  5.18it/s][A
[LS] Sample frames: 16:  67%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½   | 8/12 [00:02<00:00,  5.51it/s][A
[LS] Sample frames: 16:  75%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½  | 9/12 [00:02<00:00,  5.72it/s][A
[LS] Sample frames: 16:  83%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ | 10/12 [00:02<00:00,  5.85it/s][A
[LS] Sample frames: 16:  92%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½| 11/12 [00:02<00:00,  6.01it/s][A
[LS] Sample frames: 16: 100%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½| 12/12 [00:02<00:00,  6.15it/s][A
[LS] Sample frames: 16: 100%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½| 12/12 [00:02<00:00,  4.25it/s]
[LS] Doing inference...: 100%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½| 4/4 [00:19<00:00,  4.63s/it]
[LS] Doing inference...: 100%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½| 4/4 [00:19<00:00,  4.81s/it]
[LS] Restoring 58 faces...
[LS] 0%|          | 0/58 [00:00<?, ?it/s]
[LS] 3%|ï¿½ï¿½         | 2/58 [00:00<00:03, 16.95it/s]
[LS] 7%|ï¿½ï¿½         | 4/58 [00:00<00:02, 18.62it/s]
[LS] 10%|ï¿½ï¿½         | 6/58 [00:00<00:02, 19.21it/s]
[LS] 16%|ï¿½ï¿½ï¿½ï¿½        | 9/58 [00:00<00:02, 19.56it/s]
[LS] 19%|ï¿½ï¿½ï¿½ï¿½        | 11/58 [00:00<00:02, 19.57it/s]
[LS] 22%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½       | 13/58 [00:00<00:02, 19.67it/s]
[LS] 26%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½       | 15/58 [00:00<00:02, 19.50it/s]
[LS] 29%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½       | 17/58 [00:00<00:02, 19.46it/s]
[LS] 33%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½      | 19/58 [00:00<00:01, 19.55it/s]
[LS] 36%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½      | 21/58 [00:01<00:01, 19.40it/s]
[LS] 40%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½      | 23/58 [00:01<00:01, 19.49it/s]
[LS] 45%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½     | 26/58 [00:01<00:01, 19.47it/s]
[LS] 48%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½     | 28/58 [00:01<00:01, 19.47it/s]
[LS] 52%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½    | 30/58 [00:01<00:01, 19.21it/s]
[LS] 55%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½    | 32/58 [00:01<00:01, 19.15it/s]
[LS] 59%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½    | 34/58 [00:01<00:01, 18.70it/s]
[LS] 62%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½   | 36/58 [00:01<00:01, 18.73it/s]
[LS] 66%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½   | 38/58 [00:01<00:01, 18.95it/s]
[LS] 69%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½   | 40/58 [00:02<00:00, 18.65it/s]
[LS] 72%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½  | 42/58 [00:02<00:00, 18.95it/s]
[LS] 78%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½  | 45/58 [00:02<00:00, 19.41it/s]
[LS] 81%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½  | 47/58 [00:02<00:00, 19.49it/s]
[LS] 86%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ | 50/58 [00:02<00:00, 19.35it/s]
[LS] 90%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ | 52/58 [00:02<00:00, 19.46it/s]
[LS] 93%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½| 54/58 [00:02<00:00, 19.18it/s]
[LS] 97%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½| 56/58 [00:02<00:00, 19.22it/s]
[LS] 100%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½| 58/58 [00:03<00:00, 19.22it/s]
[LS] 100%|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½| 58/58 [00:03<00:00, 19.23it/s]
[LS] __DONE__:D:\ZhiMoAi_shuzi\unified_outputs\lipsync_1771912329.mp4
[LS] âœ… é€šè¿‡å¸¸é©»æœåŠ¡å®Œæˆæ¨ç†
[LS-SERVER] ·şÎñÒÑÍ£Ö¹£¬GPU ÏÔ´æÒÑÍêÈ«ÊÍ·Å
[GPU] TTS Ä£ĞÍÒÑĞ¶ÔØ£¬ÕıÔÚÖØĞÂ¼ÓÔØ...
>> GPT weights restored from: D:\ZhiMoAi_shuzi\_internal_tts\checkpoints\gpt.pth
>> Failed to load custom CUDA kernel for BigVGAN. Falling back to torch.
TypeError("unsupported operand type(s) for +: 'NoneType' and 'str'")
>> semantic_codec weights restored from: D:\ZhiMoAi_shuzi\_internal_tts\checkpoints\hf_cache\models--amphion--MaskGCT\snapshots\265c6cef07625665d0c28d2faafb1415562379dc\semantic_codec\model.safetensors
cfm loaded
length_regulator loaded
gpt_layer loaded
>> s2mel weights restored from: D:\ZhiMoAi_shuzi\_internal_tts\checkpoints\s2mel.pth
>> campplus_model weights restored from: D:\ZhiMoAi_shuzi\_internal_tts\checkpoints\hf_cache\models--funasr--campplus\snapshots\fb71fe990cbf6031ae6987a2d76fe64f94377b7e\campplus_cn_common.bin
Loading weights from nvidia/bigvgan_v2_22khz_80band_256x
Removing weight norm...
>> bigvgan weights restored from: nvidia/bigvgan_v2_22khz_80band_256x
>> TextNormalizer loaded
>> bpe model loaded from: D:\ZhiMoAi_shuzi\_internal_tts\checkpoints\bpe.model
[GPU] TTS Ä£ĞÍÖØĞÂ¼ÓÔØÍê³É
