[MODEL] 正在加载 IndexTTS2 声学模型...
>> GPT weights restored from: D:\ZhiMoAi_shuzi\IndexTTS2-SonicVale\checkpoints\gpt.pth
GPT2InferenceModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From \U0001f449v4.50\U0001f448 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
>> Failed to load custom CUDA kernel for BigVGAN. Falling back to torch.
TypeError("unsupported operand type(s) for +: 'NoneType' and 'str'")
>> semantic_codec weights restored from: D:\ZhiMoAi_shuzi\IndexTTS2-SonicVale\checkpoints\hf_cache\models--amphion--MaskGCT\snapshots\265c6cef07625665d0c28d2faafb1415562379dc\semantic_codec\model.safetensors
cfm loaded
length_regulator loaded
gpt_layer loaded
>> s2mel weights restored from: D:\ZhiMoAi_shuzi\IndexTTS2-SonicVale\checkpoints\s2mel.pth
>> campplus_model weights restored from: D:\ZhiMoAi_shuzi\IndexTTS2-SonicVale\checkpoints\hf_cache\models--funasr--campplus\snapshots\fb71fe990cbf6031ae6987a2d76fe64f94377b7e\campplus_cn_common.bin
Loading weights from nvidia/bigvgan_v2_22khz_80band_256x
Removing weight norm...
>> bigvgan weights restored from: nvidia/bigvgan_v2_22khz_80band_256x
>> TextNormalizer loaded
>> bpe model loaded from: D:\ZhiMoAi_shuzi\IndexTTS2-SonicVale\checkpoints\bpe.model
[MODEL] 模型加载完成，正在预热引擎...
>> starting inference...
Use the specified emotion vector
The following generation flags are not valid and may be ignored: ['length_penalty']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.53.0. You should pass an instance of `Cache` instead, e.g. `past_key_values=DynamicCache.from_legacy_cache(past_key_values)`.
  0%|          | 0/25 [00:00<?, ?it/s]  4%|         | 1/25 [00:00<00:02,  8.95it/s] 28%|       | 7/25 [00:00<00:00, 34.55it/s] 44%|     | 11/25 [00:00<00:00, 26.16it/s] 56%|    | 14/25 [00:00<00:00, 23.72it/s] 68%|   | 17/25 [00:00<00:00, 21.70it/s] 80%|  | 20/25 [00:00<00:00, 21.17it/s] 92%|| 23/25 [00:01<00:00, 20.84it/s]100%|| 25/25 [00:01<00:00, 22.02it/s]
torch.Size([1, 16128])
>> gpt_gen_time: 0.76 seconds
>> gpt_forward_time: 0.01 seconds
>> s2mel_time: 1.14 seconds
>> bigvgan_time: 0.27 seconds
>> Total inference time: 3.09 seconds
>> Generated audio length: 0.73 seconds
>> RTF: 4.2294
>> wav file saved to: D:\ZhiMoAi_shuzi\unified_outputs\_warmup.wav
[MODEL] 引擎预热完成，首次合成将直接输出
[MODEL] OK
[WARMUP] 正在预热 LatentSync 引擎...
[WARMUP] LatentSync 预热返回非零码: 1
[WARMUP] stderr: Traceback (most recent call last):
  File "<string>", line 1, in <module>
ImportError: cannot import name 'load_model' from 'latentsync.utils.util' (D:\ZhiMoAi_shuzi\LatentSync\latentsync\utils\util.py)

[TextExtractor] 后台线程已启动
[TextExtractor] WebSocket 连接已在后台初始化
[TextExtractor] 正在连接 wss://api.zhimengai.xyz/dsp
[TextExtractor] WebSocket 连接成功
[TextExtractor] 已发送注册消息
[TextExtractor] 收到注册响应: {"type":"connected","fd":103}
[TextExtractor] 收到消息: {"type":"registered","key":"2RFH-MOFU-XVTZ-N79P"}
[TextExtractor] 已发送提取请求: 1.05 05/24 SLw:/ e@B.GI 剪映视频字幕预设模板大全500款一键套用内含音效 #...
[TextExtractor] 收到消息: {"type":"ack","msg":"\u5df2\u63d0\u4ea4"}
[TextExtractor] 收到消息: {"type":"result","content":"hello,兄弟们来了，有我上次说要搭建那个实景的红包直播间啊，给大家一惊到底。\n有人说哎呀，你不露脸不行啊，露手卖不出去。\n非也啊，我以前带那个品知道吧啊。\n呃，我的一个同行啊，我的偶像，他就是全程只卖只只只露一个手，一天几千单，比我卖的好多了啊，去学习一下，不要只盯着我啊，对不对啊？\n人家就露个手啊啊，一天几千单，我都是一个小虾米...
Traceback (most recent call last):
  File "D:\ZhiMoAi_shuzi\IndexTTS2-SonicVale\installer_files\env\lib\site-packages\gradio\queueing.py", line 745, in process_events
    response = await route_utils.call_process_api(
  File "D:\ZhiMoAi_shuzi\IndexTTS2-SonicVale\installer_files\env\lib\site-packages\gradio\route_utils.py", line 349, in call_process_api
    output = await app.get_blocks().process_api(
  File "D:\ZhiMoAi_shuzi\IndexTTS2-SonicVale\installer_files\env\lib\site-packages\gradio\blocks.py", line 2123, in process_api
    result = await self.call_function(
  File "D:\ZhiMoAi_shuzi\IndexTTS2-SonicVale\installer_files\env\lib\site-packages\gradio\blocks.py", line 1630, in call_function
    prediction = await anyio.to_thread.run_sync(  # type: ignore
  File "D:\ZhiMoAi_shuzi\IndexTTS2-SonicVale\installer_files\env\lib\site-packages\anyio\to_thread.py", line 61, in run_sync
    return await get_async_backend().run_sync_in_worker_thread(
  File "D:\ZhiMoAi_shuzi\IndexTTS2-SonicVale\installer_files\env\lib\site-packages\anyio\_backends\_asyncio.py", line 2525, in run_sync_in_worker_thread
    return await future
  File "D:\ZhiMoAi_shuzi\IndexTTS2-SonicVale\installer_files\env\lib\site-packages\anyio\_backends\_asyncio.py", line 986, in run
    result = context.run(func, *args)
  File "D:\ZhiMoAi_shuzi\IndexTTS2-SonicVale\installer_files\env\lib\site-packages\gradio\utils.py", line 915, in wrapper
    response = f(*args, **kwargs)
  File "D:\ZhiMoAi_shuzi\unified_app.py", line 2043, in tts_and_save
    audio_path, log_msg, audio_for_ls_path = tts_wrap(
  File "D:\ZhiMoAi_shuzi\unified_app.py", line 1974, in tts_wrap
    raise gr.Error("请先选择音色或上传参考音频")
gradio.exceptions.Error: '请先选择音色或上传参考音频'
>> starting inference...
Use the specified emotion vector
The following generation flags are not valid and may be ignored: ['length_penalty']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
  0%|          | 0/25 [00:00<?, ?it/s] 12%|        | 3/25 [00:00<00:00, 29.88it/s] 24%|       | 6/25 [00:00<00:00, 28.03it/s] 36%|      | 9/25 [00:00<00:00, 16.95it/s] 48%|     | 12/25 [00:00<00:00, 14.24it/s] 56%|    | 14/25 [00:00<00:00, 13.40it/s] 64%|   | 16/25 [00:01<00:00, 12.70it/s] 72%|  | 18/25 [00:01<00:00, 12.27it/s] 80%|  | 20/25 [00:01<00:00, 12.03it/s] 88%| | 22/25 [00:01<00:00, 11.83it/s] 96%|| 24/25 [00:01<00:00, 11.67it/s]100%|| 25/25 [00:01<00:00, 13.31it/s]
torch.Size([1, 201472])
Use the specified emotion vector
The following generation flags are not valid and may be ignored: ['length_penalty']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
  0%|          | 0/25 [00:00<?, ?it/s]  4%|         | 1/25 [00:00<00:04,  5.92it/s] 24%|       | 6/25 [00:00<00:00, 21.85it/s] 36%|      | 9/25 [00:00<00:01, 15.21it/s] 44%|     | 11/25 [00:00<00:01, 13.52it/s] 52%|    | 13/25 [00:00<00:00, 12.65it/s] 60%|    | 15/25 [00:01<00:00, 12.01it/s] 68%|   | 17/25 [00:01<00:00, 11.63it/s] 76%|  | 19/25 [00:01<00:00, 11.34it/s] 84%| | 21/25 [00:01<00:00, 11.14it/s] 92%|| 23/25 [00:01<00:00, 10.97it/s]100%|| 25/25 [00:02<00:00, 10.81it/s]100%|| 25/25 [00:02<00:00, 11.99it/s]
torch.Size([1, 240640])
Use the specified emotion vector
The following generation flags are not valid and may be ignored: ['length_penalty']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
  0%|          | 0/25 [00:00<?, ?it/s] 20%|        | 5/25 [00:00<00:00, 39.53it/s] 36%|      | 9/25 [00:00<00:00, 16.82it/s] 48%|     | 12/25 [00:00<00:00, 14.21it/s] 56%|    | 14/25 [00:00<00:00, 13.32it/s] 64%|   | 16/25 [00:01<00:00, 12.57it/s] 72%|  | 18/25 [00:01<00:00, 11.98it/s] 80%|  | 20/25 [00:01<00:00, 11.70it/s] 88%| | 22/25 [00:01<00:00, 11.49it/s] 96%|| 24/25 [00:01<00:00, 11.35it/s]100%|| 25/25 [00:01<00:00, 12.88it/s]
torch.Size([1, 211200])
Use the specified emotion vector
The following generation flags are not valid and may be ignored: ['length_penalty']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
  0%|          | 0/25 [00:00<?, ?it/s] 20%|        | 5/25 [00:00<00:00, 46.18it/s] 40%|      | 10/25 [00:00<00:00, 17.62it/s] 52%|    | 13/25 [00:00<00:00, 15.49it/s] 60%|    | 15/25 [00:00<00:00, 14.56it/s] 68%|   | 17/25 [00:01<00:00, 14.00it/s] 76%|  | 19/25 [00:01<00:00, 13.47it/s] 84%| | 21/25 [00:01<00:00, 13.13it/s] 92%|| 23/25 [00:01<00:00, 12.90it/s]100%|| 25/25 [00:01<00:00, 12.74it/s]100%|| 25/25 [00:01<00:00, 14.48it/s]
torch.Size([1, 179456])
Use the specified emotion vector
The following generation flags are not valid and may be ignored: ['length_penalty']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
  0%|          | 0/25 [00:00<?, ?it/s] 20%|        | 5/25 [00:00<00:00, 35.53it/s] 36%|      | 9/25 [00:00<00:01, 15.02it/s] 48%|     | 12/25 [00:00<00:01, 12.51it/s] 56%|    | 14/25 [00:01<00:00, 11.75it/s] 64%|   | 16/25 [00:01<00:00, 11.18it/s] 72%|  | 18/25 [00:01<00:00, 10.82it/s] 80%|  | 20/25 [00:01<00:00, 10.53it/s] 88%| | 22/25 [00:01<00:00, 10.40it/s] 96%|| 24/25 [00:02<00:00, 10.30it/s]100%|| 25/25 [00:02<00:00, 11.59it/s]
torch.Size([1, 268800])
Use the specified emotion vector
The following generation flags are not valid and may be ignored: ['length_penalty']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
  0%|          | 0/25 [00:00<?, ?it/s] 20%|        | 5/25 [00:00<00:00, 40.37it/s] 40%|      | 10/25 [00:00<00:00, 15.50it/s] 52%|    | 13/25 [00:00<00:00, 13.48it/s] 60%|    | 15/25 [00:01<00:00, 12.67it/s] 68%|   | 17/25 [00:01<00:00, 12.15it/s] 76%|  | 19/25 [00:01<00:00, 11.73it/s] 84%| | 21/25 [00:01<00:00, 11.41it/s] 92%|| 23/25 [00:01<00:00, 11.42it/s]100%|| 25/25 [00:01<00:00, 10.99it/s]100%|| 25/25 [00:01<00:00, 12.59it/s]
torch.Size([1, 236800])
Use the specified emotion vector
The following generation flags are not valid and may be ignored: ['length_penalty']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
  0%|          | 0/25 [00:00<?, ?it/s] 20%|        | 5/25 [00:00<00:00, 39.59it/s] 36%|      | 9/25 [00:00<00:00, 17.25it/s] 48%|     | 12/25 [00:00<00:00, 14.59it/s] 56%|    | 14/25 [00:00<00:00, 13.46it/s] 64%|   | 16/25 [00:01<00:00, 12.90it/s] 72%|  | 18/25 [00:01<00:00, 12.53it/s] 80%|  | 20/25 [00:01<00:00, 12.18it/s] 88%| | 22/25 [00:01<00:00, 11.75it/s] 96%|| 24/25 [00:01<00:00, 11.72it/s]100%|| 25/25 [00:01<00:00, 13.30it/s]
torch.Size([1, 198144])
Use the specified emotion vector
The following generation flags are not valid and may be ignored: ['length_penalty']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
  0%|          | 0/25 [00:00<?, ?it/s] 20%|        | 5/25 [00:00<00:00, 39.82it/s] 36%|      | 9/25 [00:00<00:00, 16.50it/s] 48%|     | 12/25 [00:00<00:00, 14.02it/s] 56%|    | 14/25 [00:00<00:00, 12.98it/s] 64%|   | 16/25 [00:01<00:00, 12.37it/s] 72%|  | 18/25 [00:01<00:00, 11.92it/s] 80%|  | 20/25 [00:01<00:00, 11.65it/s] 88%| | 22/25 [00:01<00:00, 11.47it/s] 96%|| 24/25 [00:01<00:00, 11.37it/s]100%|| 25/25 [00:01<00:00, 12.81it/s]
torch.Size([1, 210688])
Use the specified emotion vector
The following generation flags are not valid and may be ignored: ['length_penalty']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
  0%|          | 0/25 [00:00<?, ?it/s] 20%|        | 5/25 [00:00<00:00, 40.15it/s] 40%|      | 10/25 [00:00<00:00, 16.24it/s] 52%|    | 13/25 [00:00<00:00, 14.19it/s] 60%|    | 15/25 [00:00<00:00, 13.63it/s] 68%|   | 17/25 [00:01<00:00, 13.01it/s] 76%|  | 19/25 [00:01<00:00, 12.50it/s] 84%| | 21/25 [00:01<00:00, 12.19it/s] 92%|| 23/25 [00:01<00:00, 12.02it/s]100%|| 25/25 [00:01<00:00, 11.82it/s]100%|| 25/25 [00:01<00:00, 13.41it/s]
torch.Size([1, 192256])
Use the specified emotion vector
The following generation flags are not valid and may be ignored: ['length_penalty']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
  0%|          | 0/25 [00:00<?, ?it/s] 20%|        | 5/25 [00:00<00:00, 37.23it/s] 36%|      | 9/25 [00:00<00:01, 15.97it/s] 48%|     | 12/25 [00:00<00:00, 13.45it/s] 56%|    | 14/25 [00:00<00:00, 12.55it/s] 64%|   | 16/25 [00:01<00:00, 12.04it/s] 72%|  | 18/25 [00:01<00:00, 11.62it/s] 80%|  | 20/25 [00:01<00:00, 11.20it/s] 88%| | 22/25 [00:01<00:00, 11.06it/s] 96%|| 24/25 [00:01<00:00, 10.84it/s]100%|| 25/25 [00:02<00:00, 12.36it/s]
torch.Size([1, 226304])
Use the specified emotion vector
The following generation flags are not valid and may be ignored: ['length_penalty']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
  0%|          | 0/25 [00:00<?, ?it/s] 20%|        | 5/25 [00:00<00:00, 43.76it/s] 40%|      | 10/25 [00:00<00:00, 17.08it/s] 52%|    | 13/25 [00:00<00:00, 15.02it/s] 60%|    | 15/25 [00:00<00:00, 14.21it/s] 68%|   | 17/25 [00:01<00:00, 13.59it/s] 76%|  | 19/25 [00:01<00:00, 13.18it/s] 84%| | 21/25 [00:01<00:00, 12.90it/s] 92%|| 23/25 [00:01<00:00, 12.68it/s]100%|| 25/25 [00:01<00:00, 12.58it/s]100%|| 25/25 [00:01<00:00, 14.17it/s]
torch.Size([1, 188416])
Use the specified emotion vector
The following generation flags are not valid and may be ignored: ['length_penalty']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
  0%|          | 0/25 [00:00<?, ?it/s] 20%|        | 5/25 [00:00<00:00, 37.76it/s] 36%|      | 9/25 [00:00<00:00, 16.02it/s] 48%|     | 12/25 [00:00<00:00, 13.70it/s] 56%|    | 14/25 [00:00<00:00, 12.82it/s] 64%|   | 16/25 [00:01<00:00, 12.19it/s] 72%|  | 18/25 [00:01<00:00, 11.77it/s] 80%|  | 20/25 [00:01<00:00, 11.46it/s] 88%| | 22/25 [00:01<00:00, 11.25it/s] 96%|| 24/25 [00:01<00:00, 11.10it/s]100%|| 25/25 [00:01<00:00, 12.57it/s]
torch.Size([1, 228864])
Use the specified emotion vector
The following generation flags are not valid and may be ignored: ['length_penalty']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
  0%|          | 0/25 [00:00<?, ?it/s] 20%|        | 5/25 [00:00<00:00, 42.75it/s] 40%|      | 10/25 [00:00<00:00, 17.21it/s] 52%|    | 13/25 [00:00<00:00, 15.09it/s] 60%|    | 15/25 [00:00<00:00, 14.21it/s] 68%|   | 17/25 [00:01<00:00, 13.58it/s] 76%|  | 19/25 [00:01<00:00, 13.10it/s] 84%| | 21/25 [00:01<00:00, 12.77it/s] 92%|| 23/25 [00:01<00:00, 12.59it/s]100%|| 25/25 [00:01<00:00, 12.48it/s]100%|| 25/25 [00:01<00:00, 14.11it/s]
torch.Size([1, 189184])
>> gpt_gen_time: 68.21 seconds
>> gpt_forward_time: 0.15 seconds
>> s2mel_time: 25.34 seconds
>> bigvgan_time: 2.89 seconds
>> Total inference time: 101.96 seconds
>> Generated audio length: 128.12 seconds
>> RTF: 0.7958
>> wav file saved to: D:\ZhiMoAi_shuzi\unified_outputs\tts_1771749901.wav
